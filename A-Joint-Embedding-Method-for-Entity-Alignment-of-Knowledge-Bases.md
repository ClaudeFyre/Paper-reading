---
title: A Joint Embedding Method for Entity Alignment of Knowledge Bases
date: 2021-02-27 11:51:02
tags:
---
1.Cross-lingual links construction: JE constructs a set of positive and negative entity pairs based on cross-lingual links between knowledge bases. For instance, it may use inter-language links such as Wikipedia inter-language links or cross-lingual links generated by bilingual dictionaries or machine translation systems.

2.Entity embedding learning: JE learns a low-dimensional embedding for each entity in multiple knowledge bases simultaneously by optimizing a margin-based ranking loss function. The function encourages the similarity between positive entity pairs to be high and the similarity between negative entity pairs to be low. The similarity between entities is defined as the dot product of their embeddings.

3.Joint optimization: The embeddings for all the entities are learned jointly by minimizing the margin-based ranking loss function. JE uses a stochastic gradient descent algorithm to optimize the embeddings iteratively. During each iteration, it updates the embeddings for all entities based on the gradients of the loss function.

4.Refinement and regularization: JE iteratively refines the entity alignment based on the learned embeddings by using cross-validation to tune the hyperparameters of the method. It also incorporates several additional techniques, such as regularization, to improve the performance of the method on entity alignment tasks.

Overall, JE achieves entity alignment of knowledge bases by jointly learning low-dimensional embeddings for all entities in multiple knowledge bases and optimizing the embeddings based on cross-lingual links and a margin-based ranking loss function. The method has been shown to be effective on various entity alignment tasks and is widely used as a baseline method in the field of knowledge graph research.