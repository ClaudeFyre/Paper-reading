## Paper:17




1. Title: Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment (以跨语言实体对齐为任务的知识图谱嵌入与实体描述联合训练)

2. Authors: Xiaokai Wei, Huajun Chen, Peng Dai, Le Sun and Wei Zhang

3. Affiliation: 北京大学（Peking University)

4. Keywords: Multilingual knowledge graph (多语言知识图谱), Entity alignment (实体对齐), Embedding models (嵌入模型), Cross-lingual NLP (跨语言自然语言处理), Co-training (联合训练)

5. Url: http://arxiv.org/abs/1806.06478v1 Github: None

6. Summary: 

- (1): 本文的研究背景是多语言知识图谱，它们能够提供实体的潜在语义表达，并且支持多语言之间的推理，因此对于各种知识驱动的跨语言自然语言处理任务非常有帮助。然而，实体对齐涉及到许多不同语言的知识库之间的匹配，这一过程可以说是缺乏有效的监督。因此，本文的目标在于提出一种新的联合训练方法，以实现跨语言实体对齐任务。

- (2): 过去的方法主要集中在嵌入模型上，通过将不同语言的知识库结构连接到同一向量空间内，实现跨语言学习。然而，由于跨语言知识通常只是在一定程度上匹配而不完全匹配，因此这种方法的效果很容易受到影响。本文提出了一个新的联合训练方法，充分利用知识图谱中存储的实体描述信息进行半监督学习，以提高跨语言学习的准确性。

- (3): 本文提出的联合训练方法是通过两个嵌入模型的联合学习，即多语言知识图谱嵌入模型和多语言实体描述嵌入模型，训练一个大型三语维基百科数据集的方式实现的。其中，许多实体对之间的对齐关系是未知的。通过联合训练，可以逐步提高实体对齐任务的性能，最终达到显著优于以往方法的水平。实验结果还表明，本方法有望在零样本实体对齐和跨语言知识图谱完整性方面具有潜力。

- (4): 本文提出的方法在实体对齐任务上实现了明显的优化，且在零样本任务以及跨语言知识图谱完整性方面的表现很有潜力，能够支持该领域的研究。





8. Conclusion:

- (1): 本研究意义在于提出一种新的联合训练方法，用于实现跨语言实体对齐任务。该方法通过两个嵌入模型的联合学习，充分利用知识图谱中的实体描述信息，逐步提高实体对齐任务的性能，最终达到显著优于以往方法的水平。此外，该方法在零样本任务以及跨语言知识图谱完整性方面表现出了潜力，能够支持相应领域的研究。

- (2): 创新点：本文提出了一种新的联合训练方法，充分利用多语言知识图谱和实体描述信息，提高跨语言实体对齐任务的准确性。性能：实验结果在实体对齐任务上实现了明显的优化，并具有在零样本任务和跨语言知识图谱完整性方面的潜力。工作量：实验使用的数据集较大，需要一定的计算资源和时间成本。




