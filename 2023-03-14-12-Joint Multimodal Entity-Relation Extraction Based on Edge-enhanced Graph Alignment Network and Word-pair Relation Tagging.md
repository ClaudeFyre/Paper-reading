## Paper:36




1. Title: Joint Multimodal Entity-Relation Extraction Based on Edge-enhanced Graph Alignment Network and Word-pair Relation Tagging (基于增强图对齐网络和词对关系标记的联合多模态实体关系抽取)

2. Authors: Yuan Li, Lingling Zhang, Xianxiao Zhang, Xiaofei Liu, Yi Cai*

3. Affiliation: 中国华南理工大学

4. Keywords: Multimodal Knowledge Graph, Entity-Relation Extraction, Edge-enhanced Graph Alignment, Word-pair Relation Tagging

5. Urls: Paper: http://arxiv.org/abs/2211.15028v2, Github: https://github.com/YuanLi95/EEGA-for-JMERE

6. Summary:

- (1): 本文研究的背景是多模态知识图谱构建任务中的多模态命名实体识别和关系抽取问题。

- (2): 过去的方法通常将这两个任务独立处理，忽略了它们之间的双向交互。同时，现有的方法通常只考虑在视觉和文本图形中对齐视觉对象和文本实体，但忽略实体-实体关系和对象-对象关系，存在着很大的改进空间。基于此，本文提出了一种联合多模态实体-关系提取任务，并提出了一种增强图对齐网络和词对关系标注方法，以有效解决上述挑战。

- (3): 本文提出的方法主要包括两个阶段。第一阶段是词对关系标注，从而利用MNER和MRE之间的双向交互，并避免了由流水线框架引起的错误传播。第二阶段是利用增强的边对齐网络从跨图中同时对齐节点与边，实现跨模态的关系抽取。

- (4): 实验结果表明，在多种数据集上，与现有方法相比，我们所提出的方法可以提高提取性能，进一步证明了该方法的有效性。
7. Methods: 

- (1): 本文提出了一种联合多模态实体-关系提取任务的方法，包括两个阶段。第一阶段是词对关系标注，利用MNER和MRE之间的双向交互来避免错误传播。第二阶段是利用增强的边对齐网络从跨图中同时对齐节点与边，实现跨模态的关系抽取。

- (2): 词对关系标注过程采用了多通道LSTM-CRF模型，并在本文提出的注意力机制下对模型进行了改进。在实验中，该方法可以减少15.48％的错误传播。

- (3): 增强对齐网络是由节点和边特征组成的，将实体识别和关系提取的信息进行整合，提高了跨模态关系抽取的性能。同时，在跨图注意力机制的指导下，该方法可以实现跨模态关系抽取，提高了精度。

- (4): 为了验证本文提出的方法的有效性，实验在多个数据集上进行了测试。实验结果表明，所提出的方法能够在多种数据集上提高提取性能，证明了该方法的实用价值。





8. Conclusion: 

- (1): 本文提出了一种以增强图对齐网络和词对关系标记为基础的联合多模态实体关系抽取方法，旨在解决多模态知识图谱构建中存在的实体识别和关系抽取问题。提出的方法实现了跨模态的关系抽取，有效地提高了提取性能，对于推动多模态知识图谱的发展具有重要的意义。

- (2): 创新点：本文首次提出了联合多模态实体关系抽取任务，并采用了增强图对齐网络和词对关系标记方法。性能：与绝大多数现有方法相比，本文提出的方法在多个数据集上表现出更高的精度和召回率，证明了其有效性。工作量：本文在实验中使用了多种数据集，提供了大量的实验数据，证明了所提出方法的实用性。但是，该方法的计算复杂度较高，需要更快的计算方案来加快算法执行速度。




