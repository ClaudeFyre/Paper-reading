## Paper:33




1. Title: Aligning Cross-Lingual Entities with Multi-Aspect Information （多方面信息与多语言实体对齐）

2. Authors: Xingyu Hou, Lei Hou, Juanzi Li, Zhiyuan Liu, Liang Zhao

3. Affiliation: Xingyu Hou - Department of Computer Science and Technology, Tsinghua University, Beijing, China （侯星宇 - 清华大学计算机科学与技术系，北京，中国）

4. Keywords: Cross-lingual entity alignment, multilingual knowledge graphs, graph convolutional networks, BERT, entity embeddings （多语言实体对齐，多语言知识图谱，图卷积网络，BERT，实体嵌入）

5. Urls: http://arxiv.org/abs/1910.06575v1 , Github: None.

6. Summary: 

   - (1):本文的研究背景是多语言知识图谱的实体对齐问题。目前一些多语言知识图谱如DBpedia和YAGO用许多种语言来表述，实体对齐的任务是将一个语言中的实体与其它语言中的对应实体匹配。
 
   - (2):传统方法主要采用机器翻译技术来翻译实体标签。然而，对于现有知识库的多数实体（如DBpedia中少于20%的实体），该方法的对齐效果并不好。此外，多语言知识图谱除了图结构外，还给出实体的属性和文字描述。本文通过利用这些多方面信息提出了一种基于图卷积网络与BERT嵌入相结合的新方法，来提高实体对齐的效果。
 
   - (3):本文主要采用了两个技术来实现跨语言实体对齐：图卷积网络（GCN）和BERT。采用GCN来将实体的多方面信息进行融合，包括拓扑连接、实体之间的关系和实体的属性等，产生实体嵌入。为了有效地利用不同语言中的文字描述，本文提出了两种方法来预训练多语言BERT模型，一是对翻译语句进行训练，另一种是对原文语句进行学习。本文提出两种集成GCN和BERT的策略来提高对齐性能。
  
   - (4):本文在两个基准数据集上进行了实验，并通过对获得对齐实体的精度，召回率和F1评价指标计算，实验结果表明，新方法比现有的实体对齐系统取得了更好的性能。
7. Methods: 

- (1): 本文的研究目的是解决多语言知识图谱的跨语言实体对齐问题。本文提出了一种基于图卷积网络（GCN）和BERT嵌入相结合的新方法。本文主要采用了两个技术来实现跨语言实体对齐：GCN和BERT。GCN考虑了实体的多方面信息来进行融合，包括拓扑连接、实体之间的关系和实体的属性等，产生实体嵌入。BERT则采用两种方法来预训练多语言模型，弥补GCN在文字描述方面的不足。

- (2): 本文主要考虑了多语言知识图谱的三种方面信息，即拓扑连接、实体之间的关系和实体的属性。为了有效利用这些信息进行跨语言实体对齐，本文采用了GCN来融合实体的多方面信息，将输入的特征信息通过图的方式进行传播。同时针对实体描述的问题，采用BERT来对实体描述进行处理，学习实体的句子级别的嵌入表示。本文将GCN的表示和BERT的嵌入使用不同的策略进行融合，以使跨语言实体对齐更准确。

- (3): 本文在两个基准数据集上进行了实验，并通过对获得对齐实体的精度、召回率和F1评价指标计算，实验结果表明，新方法比现有的实体对齐系统取得了更好的性能。本文的方法可以应用于多语言知识图谱的实体对齐任务，并且可以有效地处理多方面信息和文字描述信息，提高实体对齐的准确性和效率。





8. Conclusion:

- (1): 本文提出了一种基于图卷积网络和BERT嵌入相结合的新方法解决多语言知识图谱的跨语言实体对齐问题。这种方法利用实体的多方面信息和文字描述信息，提高了对齐的准确性和效率。

- (2): 创新点：本文引入了图卷积网络并结合BERT嵌入来实现跨语言实体对齐；性能：实验结果表明该方法相对于现有的实体对齐系统取得了更好的性能；工作量：本文提出的方法需要进行预训练和分组实验，具有一定的工作量。




